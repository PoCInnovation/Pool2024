{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Utils-Methode\n",
    "\n",
    "After having a little introduction to the PyTorch library, we will now implement some of the methods in the library, with the objective of understanding how they work, how they are implemented and finally getting a better understanding of the library.\n",
    "\n",
    "## Let's Start\n",
    "\n",
    "First things first, we will implement easy methods such as ReLU, LeakyReLU, and Sigmoid.\n",
    "\n",
    "Then we will implement the class MyLinear, which is a simple linear (technically, affine) transformation, and the class BatchNorm2d, which is a simple batch normalization.\n",
    "\n",
    "Finally, we will implement the class MyConv2d, which is a simple 2D convolution, and the class ConvTranspose2d, which is a simple 2D transposed convolution."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7d966e65a955a08"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from typing import Tuple, Union, List\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "IntOrPair = Union[int, Tuple[int, int]]\n",
    "Pair = Tuple[int, int]\n",
    "\n",
    "t1 = t.tensor([-1, -2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=t.float32)\n",
    "t2 = t.tensor([10, 9, 8, 7, 6, 5, 4, 3, 2, 1], dtype=t.float32)\n",
    "\n",
    "def force_pair(v: IntOrPair) -> Pair:\n",
    "    if isinstance(v, tuple):\n",
    "        if len(v) != 2:\n",
    "            raise ValueError(v)\n",
    "        return int(v[0]), int(v[1])\n",
    "    elif isinstance(v, int):\n",
    "        return (v, v)\n",
    "    raise ValueError(v)\n",
    "image = Image.new('RGB', (256, 256), (255, 255, 255))\n",
    "transform = transforms.ToTensor()\n",
    "tensor_image = transform(image)\n",
    "tensor_image = tensor_image.unsqueeze(0)\n",
    "weights = t.tensor([[[[1, 0, -1], [1, 0, -1], [1, 0, -1]], [[1, 0, -1], [1, 0, -1], [1, 0, -1]], [[1, 0, -1], [1, 0, -1], [1, 0, -1]]]], dtype=t.float32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb2624afca073dab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ReLU\n",
    "The fonction ReLu looks like this :\n",
    "![image](assets/ReLU.png)\n",
    "The principe of ReLU is to return the maximum between 0 and the input value. Why ? Because in AI, we want 3 things, the first one is to have a non-linear function, and the second one is to prevent the vanishing gradient problem(when the gradient is too small, the network doesn't learn anything), and the last one is to have more efficient computation.\n",
    "\n",
    "To have more information about ReLU and it's implementation, you can check this [link](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "118f34cc612f14e7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#implement a ReLU fonction\n",
    "def ReLU(x : t.Tensor) -> t.Tensor:\n",
    "    pass\n",
    "assert ReLU(t1).equal(t.tensor([0, 0, 3, 4, 5, 6, 7, 8, 9, 10])), \"Error in ReLU\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cef06308ce6aa517",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LeakyReLU\n",
    "The fonction LeakyReLU looks like this :\n",
    "\n",
    "![image](assets/LeakyReLU.png)\n",
    "\n",
    "The principe of LeakyReLU is to return the maximum between 0 and the input value, but with a small slope for the negative values. Why ? Because here, we want to be sure that neurons won't die (a dead neuron is a neuron that always returns the same value, and so it doesn't learn anything) and we want to use the benefits of the ReLU function and at the same time, we want to learn a bit from the negative values.\n",
    "\n",
    "To have more information about ReLU and it's implementation, you can check this [link](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4573ff484918ae02"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def MyLeakyReLU(x : t.Tensor, negative_slope : float = 0.01) -> t.Tensor:\n",
    "    pass\n",
    "assert MyLeakyReLU(t1).equal(t.tensor([-0.01, -0.02, 3, 4, 5, 6, 7, 8, 9, 10])), \"Error in LeakyReLU\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e80496989234e575",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sigmoid\n",
    "The fonction Sigmoid looks like this :\n",
    "![image](assets/Sigmoid.png)\n",
    "The principe of Sigmoid is to return a value between 0 and 1 to transform the input value into a probability and to stabilize the output of the network.\n",
    "\n",
    "To have more information about Sigmoid and it's implementation, you can check this [link](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b10fd97b4c7192ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def MySigmoid(x : t.Tensor) -> t.Tensor:\n",
    "    pass\n",
    "assert MySigmoid(t1).round(decimals=4).equal(t.tensor([0.2689, 0.1192, 0.9526, 0.9820, 0.9933, 0.9975, 0.9991, 0.9997, 0.9999, 1.0000])), \"Error in Sigmoid\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b779dcb2912ac22",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tanh\n",
    "The fonction Tanh looks like this :\n",
    "![image](assets/Tanh.png)\n",
    "The principe of Tanh is to return a value between -1 and 1 it's has the same propriety as the Sigmoid function but with a range between -1 and 1.\n",
    "\n",
    "To have more information about Tanh and it's implementation, you can check this [link](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faa40a8c953b5aea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def Tanh(x : t.Tensor) -> t.Tensor:\n",
    "    pass\n",
    "assert Tanh(t1).round(decimals=4).equal(t.tensor([-0.7616, -0.9640, 0.9951, 0.9993, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])), \"Error in Tanh\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac87645ffe1392d9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MyLinear\n",
    "The class MyLinear is a simple linear (technically, affine) transformation.\n",
    "\n",
    "It's a useful tool to modulate the simple relation between input and output characteristic.\n",
    "\n",
    "Here you will need a bit more help :\n",
    "the in_features are the dimensions of the entry vector\n",
    "\n",
    "the out_features are the dimensions of the return vector.\n",
    "\n",
    "the bias is the b that we add in the form of y = w . x + b where w is the weight and x is the input.\n",
    "\n",
    "In that exercise you will just have to implement the forward method. and you have to use the einsum method from PyTorch. and to be sure that the bias is added only if it's not None."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5994758437f4d5df"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias=True):\n",
    "        super().__init__()\n",
    "        # set all the parameters\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        \n",
    "        bound = in_features**-0.5\n",
    "        self.weight = nn.parameter.Parameter(t.empty(..., ...).uniform_(-bound, bound))\n",
    "        if bias:\n",
    "            self.bias = nn.parameter.Parameter(t.empty(...).uniform_(-bound, bound))\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    # The forward method is the same as the torch.nn.Linear use einsum method \n",
    "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
    "        pass\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}\"\n",
    "\n",
    "linear = MyLinear(3, 3)\n",
    "tensor = t.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=t.float32)\n",
    "t.manual_seed(0)\n",
    "assert linear(tensor).round(decimals=4).equal(t.tensor([[-0.6577, -0.5797,  0.6369], [-1.1670, -2.0570,  1.8222], [-1.6764, -3.5343,  3.0075]])), \"Error in MyLinear\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cd4167e85eda019",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conv2d\n",
    "The class Conv2d is a convolution in 2 dimensions. It's an essential tool for an AI model to learn be able to treat images, you should already know it with the CNN model that you made this morning ^^.\n",
    "\n",
    "Here we will do 2 things, first of all we will work on myConv2d, who is a function that make the convolution, and then we will create the class convolution, who implement that class.\n",
    "\n",
    "the padding and the stride are a bit tricky, basically, the padding is the number of pixels that we add to the input image (around the image to make the calculs), and the stride is the number of pixels that we add to make the convolution.\n",
    "\n",
    "![image](assets/padding_and_stride.gif)\n",
    "\n",
    "Here the padding is in grey, the kernel is in green, and the image is in blue. If we only use the kernel, we will have a smaller image, and so we add some pixels around the image to have the same size of the input image for the output.\n",
    " \n",
    "for more info go to check this [link](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec69a0c2502b4800"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def myConv2d(x : t.Tensor, weights : t.Tensor, stride : IntOrPair, padding : IntOrPair) -> t.Tensor:\n",
    "    # Get the stride and the padding as a pair\n",
    "    padding_height, padding_width = ...\n",
    "\n",
    "    # Get the dimensions of the input x and the weights\n",
    "    ...\n",
    "    # create the output height and output width using the formula : output = (input + 2 * padding - kernel) / stride + 1 \n",
    "    ...\n",
    "    # create a tensor with the size of the output and fill it with 0 ask for some help if you need\n",
    "    out = ...\n",
    "    # create a strided tensor from the input tensor it's a way that I recommend to do it, it's not the only one\n",
    "    out[... , # don't replace the ...\n",
    "        padding_height : padding_height + ... , # replace the ... by the correct varriable\n",
    "        padding_width : padding_width + ... ] = x # replace the ... by the correct varriable\n",
    "    \n",
    "    # create the conv_size and the conv_stride\n",
    "    conv_size = ...\n",
    "    # hint \n",
    "    batch_stride, in_chanel_stride, image_height_stride, image_width_stride = out.stride()\n",
    "    conv_stride = ...\n",
    "    strided_x = t.as_strided(out, size=conv_size, stride=conv_stride)\n",
    "\n",
    "    # and then you have to return the result of the convolution through the einsum method if you want an hint, continue to read\n",
    "    # the strided_x is a tensor with the shape (batch, out_height, out_width, in_channel, kernel_height, kernel_width)\n",
    "    # the weights is a tensor with the shape (out_channel, in_channel, kernel_height, kernel_width)\n",
    "    # the result is a tensor with the shape (batch, out_channel, out_height, out_width)\n",
    "    return ...\n",
    "\n",
    "assert myConv2d(tensor_image, weights, 1, 1).shape == (1, 1, 256, 256), \"Error in myConv2d\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24eaa1e65dba41e2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## extra_repr\n",
    "\n",
    "The extra_repr method is a method that is used to print the parameters of the class, it's a useful tool to have a better understanding of the class and to debug it.\n",
    "\n",
    "Ignore it if you don't understand it is not relevant for the exercise, but if you want to understand it, you can check this [link](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.extra_repr)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75962a1136873bea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extra_repr(module, arg_names: List[str], kwarg_names: List[str]) -> str:\n",
    "        reprs = [repr(getattr(module, arg_name)) for arg_name in arg_names] + [\n",
    "            f\"{k}={getattr(module, k)}\" for k in kwarg_names\n",
    "        ]\n",
    "        return \", \".join(reprs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e09e17e9a65a10d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MyConv2d\n",
    "\n",
    "Here you will have to implement the class MyConv2d, who is a simple 2D convolution, but ad a class."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fff519a772d0256b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MyConv2d(t.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: IntOrPair,\n",
    "        stride: IntOrPair = 1,\n",
    "        padding: IntOrPair = 0,\n",
    "    ):\n",
    "    \n",
    "        super().__init__()\n",
    "        # set all the parameters\n",
    "\n",
    "        in_features = ...\n",
    "        bound = in_features**-0.5\n",
    "        self.weight = nn.parameter.Parameter(\n",
    "            t.empty((out_channels, in_channels, *self.kernel_size)).uniform_(-bound, bound)\n",
    "        )\n",
    "\n",
    "    # The forward method is the same as the myConv2d function\n",
    "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
    "        pass\n",
    "    def extra_repr(self) -> str:\n",
    "        return extra_repr(self, [\"in_channels\", \"out_channels\"], [\"kernel_size\", \"stride\"])\n",
    "    \n",
    "assert MyConv2d(3, 3, 3, 1, 1)(tensor_image).shape == nn.Conv2d(3, 3, 3, 1, 1)(tensor_image).shape, \"Error in MyConv2d\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d81702d74dfaff66",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
