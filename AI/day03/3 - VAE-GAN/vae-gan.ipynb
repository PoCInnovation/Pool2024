{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import make_grid\n",
    "from torch.autograd import Variable\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from utils import show_and_save, vae_gan_training, dataloader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "136968dbe2239c39",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "976ec3a19197c1df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "  classname=m.__class__.__name__\n",
    "  if classname.find('Conv')!=-1:\n",
    "    m.weight.data.normal_(0.0,0.02)\n",
    "  elif classname.find('BatchNorm')!=-1:\n",
    "    m.weight.data.normal_(1.0,0.02)\n",
    "    m.bias.data.fill_(0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45447b04e9aff631"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Encoder\n",
    "\n",
    "The encoder is the first layer of our VAE-GAN, it is the \"Encoder\". Where we want to create to pass through series of different layers, until we archieve to create a latent space representation of the input image.\n",
    " **The encoder** is composed of 3 convolutional layers, with a kernel size of 5, a stride of 2 and a padding of 2.\n",
    "  The output of the last convolutional layer is then passed through a fully connected layer (think linear), which will output the mean and the logvar of the latent space representation.\n",
    "  Each convolutional layer is followed by a batch normalization layer and a LeacklyReLU activation function.\n",
    "![VAE_GAN](assets/VAE_diagram.png)\n",
    "\n",
    "A little advice, after each convolution or linear there is a batchnorm and after each batchnorm there is a ReLU but **never after the last layer of the encoder, the last layer of the decoder or the last layer of the discriminator.**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eacf2bbb1dd63355"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Encoder,self).__init__()\n",
    "    # set all the functions that you will use in the forward\n",
    "        \n",
    "  def forward(self,x):\n",
    "    batch_size=x.size()[0]\n",
    "    # the 3 first layer of the encoder in 2d\n",
    "    out = ...\n",
    "    ...\n",
    "    out=out.view(batch_size,-1)\n",
    "    # the last layer of the encoder in 1d \n",
    "    out=...\n",
    "    # the mean and the logvar of the latent space representation in 1d\n",
    "    mean=...\n",
    "    logvar=...\n",
    "      \n",
    "    return mean,logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Decoder\n",
    "\n",
    "The decoder is the second layer of our VAE-GAN, it is the \"Decoder\" class. Where we want to create to pass through series of different layers, from the latent space to try to rebuild the input image.\n",
    "**The decoder** is composed of a linear fonction and then 3 transposed convolutional layers in 2d, with a kernel size of 6, a stride of 2 and a padding of 2. And you finish by a tanh function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdba60d3b2b2ad8c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Decoder,self).__init__()\n",
    "    # set all the functions that you will use in the forward\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = ...\n",
    "    # the first layer of the decoder in 1d\n",
    "    x=x.view(-1,256,8,8)\n",
    "    # the 3 las layer of the decoder in 2d\n",
    "    x = ...\n",
    "    # the last function of the decoder\n",
    "    x=self.tanh(self.deconv4(x))\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d35fdc535bf57939"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Discriminator\n",
    "\n",
    "The discriminator is the third and last layer of our VAE-GAN, it is the \"Discriminator\" class. Where we want to create to pass through series of different layers, from the input image to try to classify if the input image is real data or fake data (generate by the generator) they are put in competition during the learning process to see who has the best results.\n",
    "**The discriminator** is composed of 4 convolutional layers, with a kernel size of 5, a stride of 2 and a padding of 2. After that, the descriminator is composed of a fully connected layer, which means a linear layers and a sigmoid function, the objective of the discriminator is to classify the input image as real or fake.\n",
    "As you may have understand, it is really similar to the encoder, because it has to do the same thing, create a latent space representation of the input image, but the discriminator has to do it in a different way, because it has to classify the input image as real or fake, so it has to be more precise than the encoder. Each convolutional layer is followed by a batch normalization layer and a LeacklyReLU activation function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "671a3c4824129b74"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Discriminator,self).__init__()\n",
    "    # set all the functions that you will use in the forward\n",
    "\n",
    "  def forward(self,x):\n",
    "    batch_size=x.size()[0]\n",
    "    # the first layer of the discriminator in 2d and don't take any batchnorm\n",
    "    x=...\n",
    "    # the 3 next layer of the discriminator in 2d similare to the encoder\n",
    "    x=...\n",
    "    ...\n",
    "    x=x.view(-1,256*8*8)\n",
    "    x1=x\n",
    "    # the last layer of the discriminator in 1d\n",
    "    x=...\n",
    "    ...\n",
    "      \n",
    "    return x,x1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ad8fb6e9480af99"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The VAE-GAN\n",
    "\n",
    "It is the combination of the three previous classes, the encoder, the decoder and the discriminator."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "853abb0e90ab8ae4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class VAE_GAN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(VAE_GAN,self).__init__()\n",
    "    self.encoder=Encoder()\n",
    "    self.decoder=Decoder()\n",
    "    self.discriminator=Discriminator()\n",
    "    self.encoder.apply(weights_init)\n",
    "    self.decoder.apply(weights_init)\n",
    "    self.discriminator.apply(weights_init)\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    bs=x.size()[0]\n",
    "    z_mean,z_logvar=self.encoder(x)\n",
    "    std = z_logvar.mul(0.5).exp_()\n",
    "    epsilon=Variable(torch.randn(bs,128)).to(device)\n",
    "    z=z_mean+std*epsilon\n",
    "    x_tilda=self.decoder(z)\n",
    "      \n",
    "    return z_mean,z_logvar,x_tilda"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "721952d786234e03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the VAE-GAN\n",
    "\n",
    "Run that to see if the that you create model is working if you don't have a powerfull computer, you can modify the number of epochs to 5 or 10 to see if the model is working and the modify the size of the dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c3a47f108a84f69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_loader=dataloader(64)\n",
    "gen=VAE_GAN().to(device)\n",
    "discrim=Discriminator().to(device)\n",
    "real_batch = next(iter(data_loader))\n",
    "show_and_save(\"training\" ,make_grid((real_batch[0]*0.5+0.5).cpu(),8))\n",
    "\n",
    "max_train=10\n",
    "\n",
    "epochs=5\n",
    "lr=3e-4\n",
    "alpha=0.1\n",
    "gamma=15\n",
    "\n",
    "vae_gan_training(gen, discrim, data_loader, epochs, lr, alpha, gamma, device, real_batch, max_train)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d236890fa54fa85"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
